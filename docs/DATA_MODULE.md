# M√≥dulo de Tratamento de Dados üìä

## √çndice
- [Vis√£o Geral](#vis√£o-geral)
- [Arquitetura do M√≥dulo](#arquitetura-do-m√≥dulo)
- [Componentes](#componentes)
- [Como Usar](#como-usar)
- [Exemplos Pr√°ticos](#exemplos-pr√°ticos)
- [Refer√™ncia da API](#refer√™ncia-da-api)
- [Boas Pr√°ticas](#boas-pr√°ticas)

## Vis√£o Geral

O m√≥dulo de tratamento de dados √© respons√°vel por todo o pipeline de processamento, desde a importa√ß√£o de arquivos at√© a grava√ß√£o no banco de dados. Foi projetado para ser extens√≠vel, robusto e f√°cil de usar.

### Caracter√≠sticas Principais
- ‚úÖ Suporte a m√∫ltiplos formatos (Excel, CSV, JSON)
- ‚úÖ Valida√ß√£o customiz√°vel de dados
- ‚úÖ Mapeamento flex√≠vel de colunas
- ‚úÖ Convers√£o inteligente de tipos
- ‚úÖ Tratamento de erros detalhado
- ‚úÖ Logging completo do processamento

## Arquitetura do M√≥dulo

```
src/data/
‚îú‚îÄ‚îÄ __init__.py           # Exports principais
‚îú‚îÄ‚îÄ mappers/              # Mapeamento de colunas
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ base.py          # ColumnMapper, TableSchema
‚îú‚îÄ‚îÄ validators/           # Valida√ß√£o de dados
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ base.py          # DataValidator, ValidationRule
‚îú‚îÄ‚îÄ converters/           # Convers√£o de tipos
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ base.py          # TypeConverter
‚îú‚îÄ‚îÄ processors/           # Pipeline de processamento
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ base.py          # DataProcessor, ProcessingResult
‚îî‚îÄ‚îÄ utils/               # Utilit√°rios
    ‚îú‚îÄ‚îÄ __init__.py
    ‚îú‚îÄ‚îÄ importer.py      # DataImporter
    ‚îî‚îÄ‚îÄ exporter.py      # DataExporter
```

## Componentes

### 1. ColumnMapper üó∫Ô∏è

O `ColumnMapper` √© respons√°vel por mapear colunas de origem (Excel, CSV) para o formato do banco de dados.

#### Conceitos Principais

**TableSchema**: Define a estrutura de uma tabela
```python
schema = TableSchema("nome_tabela", "schema_name")
```

**ColumnDefinition**: Define uma coluna
```python
column = ColumnDefinition(
    name="id",
    data_type=DataType.INTEGER,
    nullable=False,
    primary_key=True
)
```

**ColumnMapping**: Mapeia origem ‚Üí destino
```python
mapping = ColumnMapping(
    source_name="Nome Original",
    target_name="nome_limpo",
    data_type=DataType.TEXT,
    transformations=[{"type": "lowercase"}]
)
```

#### Tipos de Dados Suportados
- `TEXT`: Texto
- `INTEGER`: N√∫mero inteiro
- `FLOAT`: N√∫mero decimal
- `DECIMAL`: Decimal preciso (monet√°rio)
- `BOOLEAN`: Verdadeiro/Falso
- `DATE`: Data
- `DATETIME`: Data e hora
- `JSON`: Objeto JSON
- `ARRAY`: Lista de valores

#### Transforma√ß√µes Dispon√≠veis
- `uppercase`: Converte para mai√∫sculas
- `lowercase`: Converte para min√∫sculas
- `trim`: Remove espa√ßos extras
- `replace`: Substitui texto
- `regex`: Substitui√ß√£o com regex
- `custom`: Fun√ß√£o personalizada

### 2. DataValidator ‚úÖ

O `DataValidator` valida e sanitiza dados antes do processamento.

#### Valida√ß√µes Pr√©-definidas
- **Texto**: n√£o vazio, tamanho m√°ximo
- **N√∫meros**: inteiros, decimais, faixas
- **Datas**: formatos v√°lidos, intervalos
- **Email**: formato correto
- **CPF/CNPJ**: valida√ß√£o completa
- **Monet√°rio**: formato brasileiro

#### Criando Valida√ß√µes Customizadas
```python
validator = DataValidator()

# Adicionar regra customizada
validator.add_rule("meu_tipo", ValidationRule(
    name="regra_customizada",
    validator=lambda x: len(x) > 5,
    error_message="Deve ter mais de 5 caracteres",
    sanitizer=lambda x: x.strip().upper()
))
```

### 3. TypeConverter üîÑ

O `TypeConverter` converte dados entre diferentes formatos.

#### Convers√µes Suportadas
- String ‚Üí N√∫mero (suporta formato brasileiro)
- Excel Date ‚Üí ISO Date
- Timestamp ‚Üí DateTime
- Boolean em m√∫ltiplos formatos
- Arrays e JSON

#### Exemplo de Uso
```python
converter = TypeConverter()

# Converter valor monet√°rio brasileiro
valor = converter.to_money("R$ 1.234,56")  # Decimal('1234.56')

# Converter data Excel
data = converter.to_date(44562)  # '2022-01-01'

# Converter booleano
ativo = converter.to_boolean("Sim")  # True
```

### 4. DataProcessor üîß

O `DataProcessor` orquestra todo o pipeline de processamento.

#### Pipeline de Processamento
1. **Limpeza**: Remove dados inv√°lidos
2. **Mapeamento**: Aplica mapeamentos
3. **Valida√ß√£o**: Valida regras
4. **Convers√£o**: Converte tipos
5. **Exporta√ß√£o**: Grava resultados

#### Recursos
- Logging detalhado
- Tratamento de erros por linha
- Exporta√ß√£o de relat√≥rios
- Processamento em lotes

### 5. DataImporter/Exporter üì•üì§

Utilit√°rios para importar e exportar dados.

#### Formatos de Importa√ß√£o
- Excel (.xlsx, .xls)
- CSV (detec√ß√£o autom√°tica de delimitador)
- JSON (objetos ou arrays)

#### Formatos de Exporta√ß√£o
- CSV
- Excel (com formata√ß√£o)
- JSON
- SQL (com CREATE TABLE)
- Parquet

## Como Usar

### Exemplo B√°sico

```python
from data import *

# 1. Configurar mapeamento
mapper = ColumnMapper()
schema = TableSchema("vendas")

# Definir colunas
schema.add_column(ColumnDefinition(
    name="id",
    data_type=DataType.INTEGER,
    primary_key=True
))

schema.add_column(ColumnDefinition(
    name="produto",
    data_type=DataType.TEXT,
    nullable=False
))

schema.add_column(ColumnDefinition(
    name="valor",
    data_type=DataType.DECIMAL
))

# Mapear Excel ‚Üí Banco
schema.add_mapping(ColumnMapping(
    source_name="Nome do Produto",
    target_name="produto",
    data_type=DataType.TEXT
))

schema.add_mapping(ColumnMapping(
    source_name="Pre√ßo",
    target_name="valor",
    data_type=DataType.DECIMAL
))

mapper.register_schema(schema)

# 2. Importar dados
importer = DataImporter(mapper=mapper)
result = importer.import_excel("vendas.xlsx", table_name="vendas")

# 3. Verificar resultado
if result.status == ProcessingStatus.COMPLETED:
    print(f"‚úÖ Sucesso! {result.processed_rows} linhas processadas")
else:
    print(f"‚ùå Erro! {len(result.errors)} erros encontrados")
```

### Exemplo Avan√ßado

```python
# Configura√ß√£o completa com valida√ß√µes customizadas

# 1. Criar validador customizado
validator = DataValidator()

# Validar unidades espec√≠ficas
unidades_validas = ["LOJA A", "LOJA B", "LOJA C"]
validator.add_rule("unidade", ValidationRule(
    name="unidade_valida",
    validator=lambda x: x.upper() in unidades_validas,
    error_message=f"Unidade deve ser uma de: {', '.join(unidades_validas)}"
))

# 2. Criar conversor customizado
converter = TypeConverter()

# Registrar convers√£o especial para SKU
def convert_sku(value):
    # SKU deve ter formato: ABC-12345
    if not value:
        return None
    parts = str(value).split('-')
    if len(parts) == 2:
        return f"{parts[0].upper()}-{parts[1].zfill(5)}"
    return value

converter.register_converter("sku", convert_sku)

# 3. Configurar processador com logging
import logging

logger = logging.getLogger("ImportacaoVendas")
processor = DataProcessor(logger=logger)

# 4. Pipeline completo
importer = DataImporter(
    mapper=mapper,
    validator=validator,
    converter=converter,
    processor=processor
)

# 5. Importar com tratamento de erros
try:
    result = importer.import_excel(
        filepath="vendas_janeiro.xlsx",
        sheet_name="Dados",
        table_name="vendas",
        skiprows=2  # Pular cabe√ßalho customizado
    )
    
    # Exportar erros se houver
    if result.errors:
        processor.export_errors("erros_importacao.json")
        
    # Exportar dados processados
    if result.output_data is not None:
        exporter = DataExporter()
        exporter.export(
            data=result.output_data,
            filepath="vendas_processadas.csv",
            format="csv"
        )
        
except Exception as e:
    logger.error(f"Erro cr√≠tico: {str(e)}")
```

## Exemplos Pr√°ticos

### 1. Importar Estornos e Cancelamentos

```python
def importar_estornos():
    # Configurar schema espec√≠fico
    mapper = ColumnMapper()
    schema = TableSchema("estornos_cancelamento")
    
    # Colunas do banco
    colunas = [
        ("id", DataType.INTEGER, {"primary_key": True}),
        ("unidade", DataType.TEXT, {"nullable": False}),
        ("data", DataType.DATE, {"nullable": False}),
        ("quantidade", DataType.INTEGER, {"default": 0}),
        ("percentual", DataType.DECIMAL, {})
    ]
    
    for nome, tipo, opts in colunas:
        schema.add_column(ColumnDefinition(
            name=nome,
            data_type=tipo,
            **opts
        ))
    
    # Mapeamentos Excel ‚Üí Banco
    mappings = [
        ("UNIDADE", "unidade", DataType.TEXT, [{"type": "uppercase"}]),
        ("DIA = DATA (A)", "data", DataType.DATE, []),
        ("QUANTIDADE", "quantidade", DataType.INTEGER, []),
        ("PERCENTUAL", "percentual", DataType.DECIMAL, [
            {"type": "custom", "function": lambda x: x * 100 if x < 1 else x}
        ])
    ]
    
    for source, target, dtype, transforms in mappings:
        schema.add_mapping(ColumnMapping(
            source_name=source,
            target_name=target,
            data_type=dtype,
            transformations=transforms
        ))
    
    mapper.register_schema(schema)
    
    # Importar
    importer = DataImporter(mapper=mapper)
    return importer.import_excel(
        "Estornos e Cancelamentos.xlsx",
        table_name="estornos_cancelamento"
    )
```

### 2. Valida√ß√£o de Dados Financeiros

```python
def validar_dados_financeiros():
    validator = DataValidator()
    
    # Validar formato de moeda
    validator.add_rule("valor", ValidationRule(
        name="formato_monetario",
        validator=lambda x: DataValidator()._is_valid_money(x),
        error_message="Formato monet√°rio inv√°lido",
        sanitizer=lambda x: DataValidator()._sanitize_money(x)
    ))
    
    # Validar intervalo de datas
    from datetime import datetime, timedelta
    data_minima = datetime.now() - timedelta(days=365)
    
    validator.add_rule("data_venda", ValidationRule(
        name="data_valida",
        validator=lambda x: datetime.fromisoformat(x) >= data_minima,
        error_message=f"Data deve ser posterior a {data_minima.date()}"
    ))
    
    return validator
```

### 3. Exporta√ß√£o Multi-formato

```python
def exportar_relatorio(dados):
    exporter = DataExporter()
    
    # Exportar para m√∫ltiplos formatos
    formatos = {
        "relatorio.xlsx": "excel",
        "relatorio.csv": "csv",
        "relatorio.json": "json",
        "relatorio.sql": "sql"
    }
    
    resultados = {}
    for arquivo, formato in formatos.items():
        if formato == "sql":
            # Configura√ß√µes espec√≠ficas para SQL
            resultado = exporter.export(
                data=dados,
                filepath=arquivo,
                format=formato,
                table_name="relatorio_vendas",
                schema="public",
                batch_size=1000
            )
        else:
            resultado = exporter.export(
                data=dados,
                filepath=arquivo,
                format=formato
            )
        resultados[formato] = resultado
    
    return resultados
```

## Refer√™ncia da API

### ColumnMapper

```python
class ColumnMapper:
    def register_schema(schema: TableSchema) -> ColumnMapper
    def map_data(table_name: str, source_data: Dict) -> Dict
    def validate_mapping(table_name: str, source_columns: List[str]) -> Dict
```

### DataValidator

```python
class DataValidator:
    def add_rule(data_type: str, rule: ValidationRule) -> None
    def validate(value: Any, data_type: str) -> ValidationResult
    def validate_row(row: Dict, schema: Dict) -> Dict[str, ValidationResult]
```

### TypeConverter

```python
class TypeConverter:
    def register_converter(type_name: str, converter: Callable) -> None
    def convert(value: Any, target_type: str, **kwargs) -> Any
    def convert_dataframe(df: DataFrame, type_mapping: Dict) -> DataFrame
```

### DataProcessor

```python
class DataProcessor:
    def add_processing_step(step: Callable, name: str) -> None
    def process(data: Union[DataFrame, List, Dict]) -> ProcessingResult
    def export_errors(filepath: str, format: str = "json") -> None
    def get_summary() -> Dict
```

### DataImporter

```python
class DataImporter:
    def import_excel(filepath: str, sheet_name=0, table_name=None) -> ProcessingResult
    def import_csv(filepath: str, table_name=None, encoding='utf-8') -> ProcessingResult
    def import_json(filepath: str, table_name=None) -> ProcessingResult
    def preview_file(filepath: str, rows=10) -> DataFrame
```

### DataExporter

```python
class DataExporter:
    def export(data: DataFrame, filepath: str, format=None, **kwargs) -> Dict
    def export_multiple(datasets: Dict[str, DataFrame], base_path: str) -> Dict
    def to_buffer(df: DataFrame, format: str) -> BytesIO
```

## Boas Pr√°ticas

### 1. Sempre Validar Antes de Processar
```python
# Verificar mapeamento antes de importar
validation = mapper.validate_mapping("tabela", df.columns.tolist())
if not validation["valid"]:
    print(f"Colunas faltando: {validation['missing_required']}")
```

### 2. Use Transa√ß√µes para Importa√ß√µes Grandes
```python
# Processar em lotes
for chunk in pd.read_excel("arquivo.xlsx", chunksize=1000):
    result = importer.import_from_dataframe(chunk, "tabela")
    if result.status == ProcessingStatus.FAILED:
        break
```

### 3. Sempre Trate Erros
```python
try:
    result = importer.import_excel("dados.xlsx")
except Exception as e:
    logger.error(f"Erro na importa√ß√£o: {e}")
    # Notificar usu√°rio ou tentar recupera√ß√£o
```

### 4. Configure Logging Apropriado
```python
import logging

# Configurar logger espec√≠fico
logger = logging.getLogger("DataImport")
logger.setLevel(logging.INFO)

handler = logging.FileHandler("import.log")
formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
handler.setFormatter(formatter)
logger.addHandler(handler)

processor = DataProcessor(logger=logger)
```

### 5. Documente Seus Mapeamentos
```python
# SEMPRE documente a origem dos dados
schema.add_mapping(ColumnMapping(
    source_name="VLTOTAL",  # Campo no Excel de vendas
    target_name="valor_total",  # Campo no banco
    data_type=DataType.DECIMAL,
    transformations=[
        {"type": "custom", "function": lambda x: abs(x)}  # Sempre positivo
    ]
))
```

## Troubleshooting

### Problema: Importa√ß√£o lenta
**Solu√ß√£o**: Use processamento em chunks
```python
pd.read_excel("arquivo.xlsx", chunksize=5000)
```

### Problema: Mem√≥ria insuficiente
**Solu√ß√£o**: Use tipos de dados eficientes
```python
dtypes = {
    'codigo': 'int32',
    'valor': 'float32',
    'ativo': 'bool'
}
df = pd.read_csv("arquivo.csv", dtype=dtypes)
```

### Problema: Codifica√ß√£o incorreta
**Solu√ß√£o**: Detecte encoding automaticamente
```python
import chardet

with open('arquivo.csv', 'rb') as f:
    result = chardet.detect(f.read())
    encoding = result['encoding']

df = pd.read_csv('arquivo.csv', encoding=encoding)
```

## Pr√≥ximos Passos

1. Explore os exemplos em `/src/data/examples/`
2. Crie seus pr√≥prios mapeamentos
3. Implemente valida√ß√µes espec√≠ficas do neg√≥cio
4. Configure logging detalhado
5. Otimize para seus volumes de dados